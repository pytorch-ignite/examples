{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-distributed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9NEVKMz0v5s"
      },
      "source": [
        "<!-- ---\n",
        "title: Distributed Training with Ignite on CIFAR10 \n",
        "date: 2021-09-18\n",
        "downloads: true\n",
        "sidebar: true\n",
        "tags:\n",
        "  - single GPU\n",
        "  - multi GPUs on a single node\n",
        "  - multi GPUs on multiple nodes\n",
        "  - TPUs on Colab\n",
        "--- -->\n",
        "# Distributed Training with Ignite on CIFAR10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHmvDGFx10HT"
      },
      "source": [
        "This tutorial is a brief introduction on how you can do distributed training with Ignite on one or more CPUs, GPUs or TPUs. We will also introduce several helper functions and Ignite concepts (setup common training handlers, save to/ load from checkpoints, etc) which you can easily incorporate in your code.\n",
        "\n",
        "<!--more-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trJ7_a7f17pg"
      },
      "source": [
        "We will take a practical approach to  distributed training (specifically data distributed parallel training) in which we:  \n",
        "\n",
        ">   1. Copy the model on every GPU\n",
        ">   2. Split the dataset and fit the models on different subsets\n",
        ">   3. Communicate the gradients at each iteration to keep the models in sync\n",
        ">\n",
        "> -- <cite>[Distributed Deep Learning 101: Introduction](https://towardsdatascience.com/distributed-deep-learning-101-introduction-ebfc1bcd59d9)</cite>\n",
        "\n",
        "use train a predefined ResNet18 on CIFAR10.\n",
        "\n",
        "In this example, we show how to use Ignite to train a neural network:\n",
        "* On one or more GPUs or TPUs\n",
        "* Compute training/validation metrics\n",
        "* Log learning rate, metrics etc\n",
        "* Save the best model weights\n",
        "* Setup logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWLrQ6EH4uoD"
      },
      "source": [
        "## Download Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7k6WVw5_uts"
      },
      "source": [
        "!pip install pytorch-ignite\n",
        "!pip install clearml # Optional "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D71VkD74he9J"
      },
      "source": [
        "## Common Configuration\n",
        "\n",
        "We maintain a `config` dictionary which can be extended to store parameters required during training. You can make changes in the initial config below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bg7unvqhegL"
      },
      "source": [
        "config = {\n",
        "    \"seed\": 543,\n",
        "    \"data_path\": \"cifar10\",\n",
        "    \"output_path\": \"output-cifar10/\",\n",
        "    \"model\": \"resnet18\",\n",
        "    \"batch_size\": 512,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"num_workers\": 2,\n",
        "    \"num_epochs\": 5,\n",
        "    \"learning_rate\": 0.4,\n",
        "    \"num_warmup_epochs\": 1,\n",
        "    \"validate_every\": 3,\n",
        "    \"checkpoint_every\": 200,\n",
        "    \"backend\": None,\n",
        "    \"resume_from\": None,\n",
        "    \"log_every_iters\": 15,\n",
        "    \"nproc_per_node\": None,\n",
        "    \"stop_iteration\": None,\n",
        "    \"with_clearml\": False,\n",
        "    \"with_amp\": False,\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzuG8QAr5Djf"
      },
      "source": [
        "## Basic Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIgzky7Q7kUk"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RVISbXd_h1F"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    Pad,\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    ToTensor,\n",
        ")\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "import ignite\n",
        "import ignite.distributed as idist\n",
        "from ignite.contrib.engines import common\n",
        "from ignite.contrib.handlers import PiecewiseLinear\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.utils import manual_seed, setup_logger"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXpew9g3PUKI"
      },
      "source": [
        "### Logging\n",
        "\n",
        "First we pass a [`setup_logger()`](https://pytorch.org/ignite/utils.html#ignite.utils.setup_logger) object to `log_basic_info()` and log all basic information such as different versions, current configuration, device on current process (local rank), backend used and number of processes (world size). `idist` (`ignite.distrubted`) provides several utility functions like `get_local_rank()`, `backend()`, `get_world_size()`, etc to make this possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g61dzVvnEVvG"
      },
      "source": [
        "def log_basic_info(logger, config):\n",
        "    logger.info(f\"Train on CIFAR10\")\n",
        "    logger.info(f\"- PyTorch version: {torch.__version__}\")\n",
        "    logger.info(f\"- Ignite version: {ignite.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        # explicitly import cudnn as torch.backends.cudnn can not be pickled with hvd spawning procs\n",
        "        from torch.backends import cudnn\n",
        "\n",
        "        logger.info(\n",
        "            f\"- GPU Device: {torch.cuda.get_device_name(idist.get_local_rank())}\"\n",
        "        )\n",
        "        logger.info(f\"- CUDA version: {torch.version.cuda}\")\n",
        "        logger.info(f\"- CUDNN version: {cudnn.version()}\")\n",
        "\n",
        "    logger.info(\"\\n\")\n",
        "    logger.info(\"Configuration:\")\n",
        "    for key, value in config.items():\n",
        "        logger.info(f\"\\t{key}: {value}\")\n",
        "    logger.info(\"\\n\")\n",
        "\n",
        "    if idist.get_world_size() > 1:\n",
        "        logger.info(\"\\nDistributed setting:\")\n",
        "        logger.info(f\"\\tbackend: {idist.backend()}\")\n",
        "        logger.info(f\"\\tworld size: {idist.get_world_size()}\")\n",
        "        logger.info(\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXiYInWikTn"
      },
      "source": [
        "Next we will take the help of `auto_` methods in `idist` to make our dataloaders, model and optimizer automatically adaptable to the current configuration `backend=None` (non-distributed) or for backends like `nccl`, `gloo`, and `xla-tpu` (distributed).\n",
        "\n",
        "Note that we are free to partially use or not use `auto_` methods at all and instead implement something custom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r83mIS4QCdg"
      },
      "source": [
        "### Dataloaders\n",
        "\n",
        "Next we are going to download the train and test datasets in `data_path`, apply transforms to it and return them via `get_train_test_datasets()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3BKYL7XGpZL"
      },
      "source": [
        "def get_train_test_datasets(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        download = True\n",
        "    else:\n",
        "        download = True if len(os.listdir(path)) < 1 else False\n",
        "\n",
        "    train_transform = Compose(\n",
        "        [\n",
        "            Pad(4),\n",
        "            RandomCrop(32, fill=128),\n",
        "            RandomHorizontalFlip(),\n",
        "            ToTensor(),\n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "    test_transform = Compose(\n",
        "        [\n",
        "            ToTensor(),\n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_ds = datasets.CIFAR10(\n",
        "        root=path, train=True, download=download, transform=train_transform\n",
        "    )\n",
        "    test_ds = datasets.CIFAR10(\n",
        "        root=path, train=False, download=False, transform=test_transform\n",
        "    )\n",
        "\n",
        "    return train_ds, test_ds"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GkEcAYiRbgO"
      },
      "source": [
        "The main logic lies in `get_dataflow()` where we have to make sure only the main process (`rank = 0`) downloads the datasets and therefore all sub processes (`rank > 0`) will get a copy of this already downloaded dataset. For this we use [`idist.barrier()`](https://pytorch.org/ignite/distributed.html#ignite.distributed.utils.barrier) to sync up all sub processes except the main one, so that it can go on downloading the dataset. Once that is done, we sync up the main process via `idist.barrier()` too.\n",
        "\n",
        "We finally pass our dataset to [`auto_dataloader()`](https://pytorch.org/ignite/generated/ignite.distributed.auto.auto_dataloader.html#ignite.distributed.auto.auto_dataloader)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rNV-UDwRPtO"
      },
      "source": [
        "def get_dataflow(config):\n",
        "    if idist.get_local_rank() > 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    train_dataset, test_dataset = get_train_test_datasets(config[\"data_path\"])\n",
        "\n",
        "    if idist.get_local_rank() == 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    train_loader = idist.auto_dataloader(\n",
        "        train_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        num_workers=config[\"num_workers\"],\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = idist.auto_dataloader(\n",
        "        test_dataset,\n",
        "        batch_size=2 * config[\"batch_size\"],\n",
        "        num_workers=config[\"num_workers\"],\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNLvDK-cS2sH"
      },
      "source": [
        "### Model\n",
        "\n",
        "`get_model()` contains the model code which is then passed to [`auto_model()`](https://pytorch.org/ignite/generated/ignite.distributed.auto.auto_model.html#auto-model) which makes it automatically adaptable for non-distributed and distributed configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toShlIcW5oFd"
      },
      "source": [
        "def get_model(config):\n",
        "    model_name = config[\"model\"]\n",
        "    if model_name in models.__dict__:\n",
        "        fn = models.__dict__[model_name]\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown model name {model_name}\")\n",
        "\n",
        "    model = idist.auto_model(fn(num_classes=10))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V14TfyCT8jQW"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "Then we can setup the optimizer using hyperameters from `config` and passing it through [`auto_optim()`](https://pytorch.org/ignite/generated/ignite.distributed.auto.auto_optim.html#ignite.distributed.auto.auto_optim)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iddv29eh5qU9"
      },
      "source": [
        "def get_optimizer(config, model):\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=config[\"learning_rate\"],\n",
        "        momentum=config[\"momentum\"],\n",
        "        weight_decay=config[\"weight_decay\"],\n",
        "        nesterov=True,\n",
        "    )\n",
        "    optimizer = idist.auto_optim(optimizer)\n",
        "\n",
        "    return optimizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI0o7hgr8l9q"
      },
      "source": [
        "### Criterion\n",
        "\n",
        "We pass the loss function to `device`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVDKkYqS5siE"
      },
      "source": [
        "def get_criterion():\n",
        "    return nn.CrossEntropyLoss().to(idist.device())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9No0Ockx8oRC"
      },
      "source": [
        "### LR Scheduler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcYuVeYic_e7"
      },
      "source": [
        "def get_lr_scheduler(config, optimizer):\n",
        "    le = config[\"num_iters_per_epoch\"]\n",
        "    milestones_values = [\n",
        "        (0, 0.0),\n",
        "        (le * config[\"num_warmup_epochs\"], config[\"learning_rate\"]),\n",
        "        (le * config[\"num_epochs\"], 0.0),\n",
        "    ]\n",
        "    lr_scheduler = PiecewiseLinear(\n",
        "        optimizer, param_name=\"lr\", milestones_values=milestones_values\n",
        "    )\n",
        "    return lr_scheduler"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjVYZdn49PKD"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp6sWINP9CAq"
      },
      "source": [
        "### Save Models\n",
        "\n",
        "We can create checkpoints using either of the two handlers:\n",
        "\n",
        "1. If `with-clearml=True`, we will save the models in ClearML's File Server using [`ClearMLSaver()`](https://pytorch.org/ignite/generated/ignite.contrib.handlers.clearml_logger.html#ignite.contrib.handlers.clearml_logger.ClearMLSaver).\n",
        "2. Else save the models to disk using [`DiskSaver()`](https://pytorch.org/ignite/generated/ignite.handlers.DiskSaver.html#ignite.handlers.DiskSaver)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DG0Pj4pJJFw"
      },
      "source": [
        "def get_save_handler(config):\n",
        "    if config[\"with_clearml\"]:\n",
        "        from ignite.contrib.handlers.clearml_logger import ClearMLSaver\n",
        "\n",
        "        return ClearMLSaver(dirname=config[\"output_path\"])\n",
        "\n",
        "    return DiskSaver(config[\"output_path\"], require_empty=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1N1iR2f9R0n"
      },
      "source": [
        "### Resume from Checkpoint\n",
        "\n",
        "If a checkpoint file path is provided, we can resume training from there by loading the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9La55z97PVa"
      },
      "source": [
        "def load_checkpoint(resume_from):\n",
        "    checkpoint_fp = Path(resume_from)\n",
        "    assert (\n",
        "        checkpoint_fp.exists()\n",
        "    ), f\"Checkpoint '{checkpoint_fp.as_posix()}' is not found\"\n",
        "    logger.info(f\"Resume from a checkpoint: {checkpoint_fp.as_posix()}\")\n",
        "    checkpoint = torch.load(checkpoint_fp.as_posix(), map_location=\"cpu\")\n",
        "    return checkpoint"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBd6WDVE_KmO"
      },
      "source": [
        "### Create Trainer\n",
        "\n",
        "Finally, we can create our `trainer` in four steps:\n",
        "1. Choose whether to enable [Automatic Mixed Precision](https://pytorch.org/docs/stable/amp.html) (AMP) or not. Enabling AMP will speed up computations on large neural networks and reduce memory usage while retaining performance. A `GradScaler()` object will be created to scale the `loss` so that gradients don't round-up to zero while training. \n",
        "2. Define steps taken to process single batch (`train_step()`)\n",
        "  1. Move the batch to `device` used in current distributed configuration.\n",
        "  2. Put `model` in `train()` mode.\n",
        "  3. Perform forward pass by passing the inputs (`x`) through the `model` and calculating `loss`. If AMP is enabled then this step happens with [`autocast`](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.autocast) on which allows this step to run in mixed precision.\n",
        "  4. Perform backward pass. If AMP is enabled, then the losses will be [scaled](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.scale) before calling `backward()`, `step()` the optimizer while discarding batches that contain NaNs and [update()](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.update) the scale for next iteration.\n",
        "3. Setup some common Ignite training handlers. You can do this individually or use a utitility function that takes the `trainer`:\n",
        "  * A dictionary mapping on what to save in the checkpoint (`to_save`) and how often (`save_every_iters`).\n",
        "  * LR Scheduler\n",
        "  * \n",
        "4. If `resume_from` file path is provided, load the states of objects `to_save` from the checkpoint file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptmfSvESbEPE"
      },
      "source": [
        "def create_trainer(\n",
        "    model, optimizer, criterion, lr_scheduler, train_sampler, config, logger\n",
        "):\n",
        "\n",
        "    device = idist.device()\n",
        "\n",
        "    with_amp = config[\"with_amp\"]\n",
        "    scaler = GradScaler(enabled=with_amp)\n",
        "\n",
        "    def train_step(engine, batch):\n",
        "\n",
        "        x, y = batch[0], batch[1]\n",
        "        if x.device != device:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with autocast(enabled=with_amp):\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()  # If with_amp=False, this is equivalent to loss.backward()\n",
        "        scaler.step(optimizer)  # If with_amp=False, this is equivalent to optimizer.step()\n",
        "        scaler.update()  # If with_amp=False, this step does nothing\n",
        "\n",
        "        return {\n",
        "            \"batch loss\": loss.item(),\n",
        "        }\n",
        "\n",
        "    trainer = Engine(train_step)\n",
        "    trainer.logger = logger\n",
        "\n",
        "    to_save = {\n",
        "        \"trainer\": trainer,\n",
        "        \"model\": model,\n",
        "        \"optimizer\": optimizer,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "    }\n",
        "    metric_names = [\n",
        "        \"batch loss\",\n",
        "    ]\n",
        "\n",
        "    common.setup_common_training_handlers(\n",
        "        trainer=trainer,\n",
        "        train_sampler=train_sampler,\n",
        "        to_save=to_save,\n",
        "        save_every_iters=config[\"checkpoint_every\"],\n",
        "        save_handler=get_save_handler(config),\n",
        "        lr_scheduler=lr_scheduler,\n",
        "        output_names=metric_names if config[\"log_every_iters\"] > 0 else None,\n",
        "        with_pbars=False,\n",
        "        clear_cuda_cache=False,\n",
        "    )\n",
        "\n",
        "    if config[\"resume_from\"] is not None:\n",
        "        checkpoint = load_checkpoint(config[\"resume_from\"])\n",
        "        Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ius6EM9aiG"
      },
      "source": [
        "## Evaluator\n",
        "\n",
        "The evaluator will be created from `evaluate_step` which will:\n",
        "1. Set the `model` to `eval()` mode.\n",
        "2. Move the batch to `device` used in current distributed configuration.\n",
        "3. Perform forward pass. If AMP is enabled, `autocast` will be on.\n",
        "\n",
        "Finally, we will attach relevant Ignite metrics to the `evaluator`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPVzU6CqNlE4"
      },
      "source": [
        "def create_evaluator(model, metrics, config):\n",
        "    with_amp = config[\"with_amp\"]\n",
        "    device = idist.device()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_step(engine, batch):\n",
        "        model.eval()\n",
        "        x, y = batch[0], batch[1]\n",
        "        if x.device != device:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "        with autocast(enabled=with_amp):\n",
        "            y_pred = model(x)\n",
        "        return y_pred, y\n",
        "\n",
        "    evaluator = Engine(evaluate_step)\n",
        "\n",
        "    for name, metric in metrics.items():\n",
        "        metric.attach(evaluator, name)\n",
        "\n",
        "    return evaluator"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opzRc2DR9dz-"
      },
      "source": [
        "## Training\n",
        "\n",
        "Before we begin training, we must setup a few things on the master process (`rank` = 0):\n",
        "* Create folder to store checkpoints, best models and output of tensorboard logging in the format - model_backend_rank_time.\n",
        "* Log `device` name.\n",
        "* If ClearML FileServer is used to save models, then a `Task` has to be created, and we pass our `config` dictionary and the specific hyper parameters that are part of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_ahtRZ_i-k8"
      },
      "source": [
        "def setup_rank_zero(logger, local_rank, config):\n",
        "    device = idist.device()\n",
        "\n",
        "    if config[\"stop_iteration\"] is None:\n",
        "        now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    else:\n",
        "        now = f\"stop-on-{config['stop_iteration']}\"\n",
        "\n",
        "    output_path = config[\"output_path\"]\n",
        "    folder_name = (\n",
        "        f\"{config['model']}_backend-{idist.backend()}-{idist.get_world_size()}_{now}\"\n",
        "    )\n",
        "    output_path = Path(output_path) / folder_name\n",
        "    if not output_path.exists():\n",
        "        output_path.mkdir(parents=True)\n",
        "    config[\"output_path\"] = output_path.as_posix()\n",
        "    logger.info(f\"Output path: {config['output_path']}\")\n",
        "\n",
        "    if \"cuda\" in device.type:\n",
        "        config[\"cuda device name\"] = torch.cuda.get_device_name(local_rank)\n",
        "\n",
        "    if config[\"with_clearml\"]:\n",
        "        try:\n",
        "            from clearml import Task\n",
        "        except ImportError:\n",
        "            # Backwards-compatibility for legacy Trains SDK\n",
        "            from trains import Task\n",
        "\n",
        "        task = Task.init(\"CIFAR10-Training\", task_name=output_path.stem)\n",
        "        task.connect_configuration(config)\n",
        "        # Log hyper parameters\n",
        "        hyper_params = [\n",
        "            \"model\",\n",
        "            \"batch_size\",\n",
        "            \"momentum\",\n",
        "            \"weight_decay\",\n",
        "            \"num_epochs\",\n",
        "            \"learning_rate\",\n",
        "            \"num_warmup_epochs\",\n",
        "        ]\n",
        "        task.connect({k: v for k, v in config.items()})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QT7tiAcJEk0"
      },
      "source": [
        "This is a standard utility function to log `train` and `val` metrics after `validate_every` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hqmFjOJN8kK"
      },
      "source": [
        "def log_metrics(logger, epoch, elapsed, tag, metrics):\n",
        "    metrics_output = \"\\n\".join([f\"\\t{k}: {v}\" for k, v in metrics.items()])\n",
        "    logger.info(\n",
        "        f\"\\nEpoch {epoch} - Evaluation time (seconds): {elapsed:.2f} - {tag} metrics:\\n {metrics_output}\"\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKzNAa1JVRR"
      },
      "source": [
        "This is where the main logic resides, i.e., we will call all the above functions from within here:\n",
        "1. Basic Setup\n",
        "  1. We set a [`manual_seed()`]() and [`setup_logger`()](), then log all basic information.\n",
        "  2. Initialise `dataloaders`, `model`, `optimizer`, `criterion` and `lr_scheduler`.\n",
        "2. We use the above objects to create a `trainer`.\n",
        "3. Evaluator\n",
        "  1. Define some relevant Ignite metrics like `Accuracy()` and `Loss()`.\n",
        "  2. Create two evaluators: `train_evaluator` and `val_evaluator` to compute metrics on the `train_dataloader` and `val_dataloader` respectively, however `val_evaluator` will store the best models based on validation metrics.\n",
        "  3. Define `run_validation()` to compute metrics on both dataloaders and log them. Then we attach this function to `trainer` to run after `validate_every` epochs and after training is complete.\n",
        "4. Setup TensorBoard logging using `setup_tb_logging()` on the master process for the trainer and evaluators so that training and validation metrics along with the learning rate can be logged.\n",
        "5. Define `Checkpoint()` object to store the two best models by validation accuracy (defined in `metrics` as `Accuracy()`) and attach it to `val_evaluator` so that it can be executed everytime `val_evaluator` runs.\n",
        "6. Stop training, if given, once it reaches `stop_iteration` using `terminate()`.\n",
        "7. Try training on `train_loader` for `num_epochs`\n",
        "8. Close Tensorboard logger once training is completed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3l1U7_vL8pg"
      },
      "source": [
        "def training(local_rank, config):\n",
        "\n",
        "    rank = idist.get_rank()\n",
        "    manual_seed(config[\"seed\"] + rank)\n",
        "\n",
        "    logger = setup_logger(name=\"CIFAR10-Training\")\n",
        "    log_basic_info(logger, config)\n",
        "\n",
        "    if rank == 0:\n",
        "        setup_rank_zero(logger, local_rank, config)\n",
        "\n",
        "    train_loader, val_loader = get_dataflow(config)\n",
        "    model = get_model(config)\n",
        "    optimizer = get_optimizer(config, model)\n",
        "    criterion = get_criterion()\n",
        "    config[\"num_iters_per_epoch\"] = len(train_loader)\n",
        "    lr_scheduler = get_lr_scheduler(config, optimizer)\n",
        "\n",
        "    trainer = create_trainer(\n",
        "        model, optimizer, criterion, lr_scheduler, train_loader.sampler, config, logger\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": Accuracy(),\n",
        "        \"Loss\": Loss(criterion),\n",
        "    }\n",
        "\n",
        "    train_evaluator = create_evaluator(model, metrics, config)\n",
        "    val_evaluator = create_evaluator(model, metrics, config)\n",
        "\n",
        "    def run_validation(engine):\n",
        "        epoch = trainer.state.epoch\n",
        "        state = train_evaluator.run(train_loader)\n",
        "        log_metrics(logger, epoch, state.times[\"COMPLETED\"], \"train\", state.metrics)\n",
        "        state = val_evaluator.run(val_loader)\n",
        "        log_metrics(logger, epoch, state.times[\"COMPLETED\"], \"val\", state.metrics)\n",
        "\n",
        "    trainer.add_event_handler(\n",
        "        Events.EPOCH_COMPLETED(every=config[\"validate_every\"]) | Events.COMPLETED,\n",
        "        run_validation,\n",
        "    )\n",
        "\n",
        "    if rank == 0:\n",
        "        evaluators = {\"train\": train_evaluator, \"val\": val_evaluator}\n",
        "        tb_logger = common.setup_tb_logging(\n",
        "            config[\"output_path\"], trainer, optimizer, evaluators=evaluators\n",
        "        )\n",
        "\n",
        "    best_model_handler = Checkpoint(\n",
        "        {\"model\": model},\n",
        "        get_save_handler(config),\n",
        "        filename_prefix=\"best\",\n",
        "        n_saved=2,\n",
        "        global_step_transform=global_step_from_engine(trainer),\n",
        "        score_name=\"val_accuracy\",\n",
        "        score_function=Checkpoint.get_default_score_fn(\"Accuracy\"),\n",
        "    )\n",
        "    val_evaluator.add_event_handler(\n",
        "        Events.COMPLETED,\n",
        "        best_model_handler,\n",
        "    )\n",
        "\n",
        "    if config[\"stop_iteration\"] is not None:\n",
        "\n",
        "        @trainer.on(Events.ITERATION_STARTED(once=config[\"stop_iteration\"]))\n",
        "        def _():\n",
        "            logger.info(f\"Stop training on {trainer.state.iteration} iteration\")\n",
        "            trainer.terminate()\n",
        "\n",
        "    try:\n",
        "        trainer.run(train_loader, max_epochs=config[\"num_epochs\"])\n",
        "    except Exception as e:\n",
        "        logger.exception(\"\")\n",
        "        raise e\n",
        "\n",
        "    if rank == 0:\n",
        "        tb_logger.close()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WioiRM5U9ipQ"
      },
      "source": [
        "## Run with Different Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhmj6meIMk2w"
      },
      "source": [
        "spawn_kwargs = {}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99enig2IdNiF"
      },
      "source": [
        "### Single CPU or GPU\n",
        "\n",
        "If on Colab, go to Runtime > Change runtime type and select Hardware accelerator = None for CPU or GPU for cuda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65P9h2A4MoT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39591f3d-31a9-4e7a-cdb5-9a3fdfe7908a"
      },
      "source": [
        "spawn_kwargs[\"nproc_per_node\"] = None\n",
        "with idist.Parallel(backend=config[\"backend\"], **spawn_kwargs) as parallel:\n",
        "    parallel.run(training, config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-30 19:31:31,924 ignite.distributed.launcher.Parallel INFO: - Run '<function training at 0x7f159497ac20>' in 1 processes\n",
            "2021-08-30 19:31:31,931 CIFAR10-Training INFO: Train on CIFAR10\n",
            "2021-08-30 19:31:31,933 CIFAR10-Training INFO: - PyTorch version: 1.9.0+cu102\n",
            "2021-08-30 19:31:31,936 CIFAR10-Training INFO: - Ignite version: 0.4.6\n",
            "2021-08-30 19:31:31,939 CIFAR10-Training INFO: \n",
            "\n",
            "2021-08-30 19:31:31,941 CIFAR10-Training INFO: Configuration:\n",
            "2021-08-30 19:31:31,944 CIFAR10-Training INFO: \tseed: 543\n",
            "2021-08-30 19:31:31,946 CIFAR10-Training INFO: \tdata_path: cifar10\n",
            "2021-08-30 19:31:31,947 CIFAR10-Training INFO: \toutput_path: output-cifar10/\n",
            "2021-08-30 19:31:31,948 CIFAR10-Training INFO: \tmodel: resnet18\n",
            "2021-08-30 19:31:31,951 CIFAR10-Training INFO: \tbatch_size: 512\n",
            "2021-08-30 19:31:31,953 CIFAR10-Training INFO: \tmomentum: 0.9\n",
            "2021-08-30 19:31:31,955 CIFAR10-Training INFO: \tweight_decay: 0.0001\n",
            "2021-08-30 19:31:31,956 CIFAR10-Training INFO: \tnum_workers: 2\n",
            "2021-08-30 19:31:31,958 CIFAR10-Training INFO: \tnum_epochs: 5\n",
            "2021-08-30 19:31:31,959 CIFAR10-Training INFO: \tlearning_rate: 0.4\n",
            "2021-08-30 19:31:31,961 CIFAR10-Training INFO: \tnum_warmup_epochs: 1\n",
            "2021-08-30 19:31:31,968 CIFAR10-Training INFO: \tvalidate_every: 3\n",
            "2021-08-30 19:31:31,969 CIFAR10-Training INFO: \tcheckpoint_every: 200\n",
            "2021-08-30 19:31:31,971 CIFAR10-Training INFO: \tbackend: None\n",
            "2021-08-30 19:31:31,973 CIFAR10-Training INFO: \tresume_from: None\n",
            "2021-08-30 19:31:31,975 CIFAR10-Training INFO: \tlog_every_iters: 15\n",
            "2021-08-30 19:31:31,976 CIFAR10-Training INFO: \tnproc_per_node: None\n",
            "2021-08-30 19:31:31,978 CIFAR10-Training INFO: \tstop_iteration: None\n",
            "2021-08-30 19:31:31,980 CIFAR10-Training INFO: \twith_clearml: False\n",
            "2021-08-30 19:31:31,981 CIFAR10-Training INFO: \twith_amp: False\n",
            "2021-08-30 19:31:31,983 CIFAR10-Training INFO: \n",
            "\n",
            "2021-08-30 19:31:31,986 CIFAR10-Training INFO: Output path: output-cifar10/resnet18_backend-None-1_20210830-193131\n",
            "2021-08-30 19:31:33,153 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 512, 'num_workers': 2, 'shuffle': True, 'drop_last': True, 'pin_memory': False}\n",
            "2021-08-30 19:31:33,155 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 1024, 'num_workers': 2, 'shuffle': False, 'pin_memory': False}\n",
            "2021-08-30 19:31:33,347 CIFAR10-Training INFO: Engine run starting with max_epochs=5.\n",
            "2021-08-30 19:40:35,460 CIFAR10-Training INFO: Epoch[1] Complete. Time taken: 00:09:02\n",
            "2021-08-30 19:49:40,749 CIFAR10-Training INFO: Epoch[2] Complete. Time taken: 00:09:05\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nxfg7j7deRD"
      },
      "source": [
        "### Single Node, Multiple GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlVEECk_kNs7"
      },
      "source": [
        "spawn_kwargs[\"nproc_per_node\"] = 2 # For 2 GPUs\n",
        "config[\"backend\"] = \"nccl\" # Find out all supported backends via ignite.distributed.utils.available_backends()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoLHt5LxlT-C"
      },
      "source": [
        "**Note:** If using \n",
        "\n",
        "```bash\n",
        "python -m torch.distributed.launch --nproc_per_node=2 --use_env main.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-jBxovGdee1"
      },
      "source": [
        "### Multiple Nodes, Multiple GPUs\n",
        "\n",
        "```python\n",
        "python -u -m torch.distributed.launch \\\n",
        "    --nnodes=2 \\\n",
        "    --nproc_per_node=2 \\\n",
        "    --node_rank=0 \\\n",
        "    --master_addr=master --master_port=2222 --use_env \\\n",
        "    main.py run --backend=\"nccl\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6s0Rn_mdewW"
      },
      "source": [
        "### TPUs on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6e2NW3kofu8"
      },
      "source": [
        "spawn_kwargs[\"nproc_per_node\"] = 8\n",
        "spawn_kwargs[\"start_method\"] = \"fork\"\n",
        "config[\"backend\"] = \"gloo\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJC98__zqwze"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "trrSIC-Qot4Z",
        "outputId": "fee257b8-fbe8-4862-c8e8-10c013a5646a"
      },
      "source": [
        "with idist.Parallel(backend=config[\"backend\"], **spawn_kwargs) as parallel:\n",
        "    parallel.run(training, config)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-405f9f399f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0midist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mspawn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/launcher.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;34mf\"Spawn function '{func}' in {self._spawn_params['nproc_per_node']} processes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             )\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0midist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Run '{func}' in {idist.get_world_size()} processes\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/utils.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(backend, fn, args, kwargs_dict, nproc_per_node, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         comp_model_cls.spawn(\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc_per_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnproc_per_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         )\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/comp_models/native.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, kwargs_dict, nproc_per_node, nnodes, node_rank, master_addr, master_port, backend, init_method, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 ),\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mspawn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             )\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ready = multiprocessing.connection.wait(\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}