{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YQCt0TA0uaNc",
   "metadata": {
    "id": "YQCt0TA0uaNc"
   },
   "source": [
    "<!-- ---\n",
    "title: How to create Custom Events based on Forward or Backward Pass\n",
    "weight: 8\n",
    "downloads: true\n",
    "sidebar: true\n",
    "summary: Learn how to create custom events that depend on the loss calculated, backward pass, optimization step, etc.\n",
    "tags:\n",
    "  - custom events\n",
    "--- -->\n",
    "# How to create Custom Events based on Forward or Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aMOY2iPOuaNk",
   "metadata": {
    "id": "aMOY2iPOuaNk"
   },
   "source": [
    "This guide demonstrates how you can create [custom events](https://pytorch.org/ignite/concepts.html#custom-events) that depend on the loss calculated and backward pass.\n",
    "\n",
    "In this example, we will be using a ResNet18 model on the MNIST dataset. The base code is the same as used in the [Getting Started Guide](https://pytorch-ignite.ai/tutorials/getting-started/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "THcUNAgpWMDF",
   "metadata": {
    "id": "THcUNAgpWMDF"
   },
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Y0sJP9iFa1TB",
   "metadata": {
    "id": "Y0sJP9iFa1TB",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.engine import Engine, EventEnum, Events, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import Timer\n",
    "from ignite.contrib.handlers import BasicTimeProfiler, HandlersTimeProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iK_9cOP6a1TI",
   "metadata": {
    "id": "iK_9cOP6a1TI"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = resnet18(num_classes=10)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q_u0IS8q9IY-",
   "metadata": {
    "id": "Q_u0IS8q9IY-"
   },
   "source": [
    "## Create Custom Events\n",
    "\n",
    "First let's create a few custom events based on backpropogation. All user-defined custom events should inherit from the base class [`EventEnum`](https://pytorch.org/ignite/generated/ignite.engine.events.EventEnum.html#ignite.engine.events.EventEnum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "TbEoK_H8yIAj",
   "metadata": {
    "id": "TbEoK_H8yIAj"
   },
   "outputs": [],
   "source": [
    "class BackpropEvents(EventEnum):\n",
    "    BACKWARD_STARTED = 'backward_started'\n",
    "    BACKWARD_COMPLETED = 'backward_completed'\n",
    "    OPTIM_STEP_COMPLETED = 'optim_step_completed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9lwr621Y9Lnx",
   "metadata": {
    "id": "9lwr621Y9Lnx"
   },
   "source": [
    "## Create `trainer`\n",
    "\n",
    "Then we define the `train_step` function to be applied on all batches. Within this, we use [`fire_event`](https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine.fire_event) to execute all handlers related to a specific event at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aqUFTEdxxvz",
   "metadata": {
    "id": "8aqUFTEdxxvz"
   },
   "outputs": [],
   "source": [
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    engine.fire_event(BackpropEvents.BACKWARD_STARTED)\n",
    "    loss.backward()\n",
    "    engine.fire_event(BackpropEvents.BACKWARD_COMPLETED)\n",
    "\n",
    "    optimizer.step()\n",
    "    engine.fire_event(BackpropEvents.OPTIM_STEP_COMPLETED)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "trainer = Engine(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eiLRGHAK9Q12",
   "metadata": {
    "id": "eiLRGHAK9Q12"
   },
   "source": [
    "## Register Custom Events in `trainer`\n",
    "\n",
    "Finally, to make sure our events can be fired, we register them in `trainer` using [`register_events`](https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine.register_events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4byi6J6N9d4K",
   "metadata": {
    "id": "4byi6J6N9d4K"
   },
   "outputs": [],
   "source": [
    "trainer.register_events(*BackpropEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WZbJwRUD9e-d",
   "metadata": {
    "id": "WZbJwRUD9e-d"
   },
   "source": [
    "## Attach handlers to Custom Events\n",
    "\n",
    "And now we can easily attach handlers to be executed when a particular event like `BACKWARD_COMPLETED` is fired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9Dp6QBfQysOq",
   "metadata": {
    "id": "9Dp6QBfQysOq"
   },
   "outputs": [],
   "source": [
    "@trainer.on(BackpropEvents.BACKWARD_COMPLETED)\n",
    "def function_before_backprop(engine):\n",
    "    print(f\"Iter[{engine.state.iteration}] Function fired after backward pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XMKXagQk-VLl",
   "metadata": {
    "id": "XMKXagQk-VLl"
   },
   "source": [
    "And finally you can run the `trainer` for some epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3G9DV6h767fj",
   "metadata": {
    "id": "3G9DV6h767fj"
   },
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x031SkP2-Lg9",
   "metadata": {
    "id": "x031SkP2-Lg9"
   },
   "source": [
    "## Additional Links\n",
    "\n",
    "You can also checkout the source code of [TBPTT Trainer](https://pytorch.org/ignite/_modules/ignite/contrib/engines/tbptt.html#create_supervised_tbptt_trainer) for a detailed explanation."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "08-custom-events.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
