{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ---\n",
    "title: How to use Loggers\n",
    "date: 2021-10-25\n",
    "downloads: true\n",
    "weight: 10\n",
    "summary: \n",
    "tags:\n",
    "  - loggers\n",
    "  - ClearML\n",
    "--- -->\n",
    "\n",
    "# How to use Loggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This how-to guide demonstrates the usage of loggers with Ignite. As part of this guide, we will be using the [ClearML](https://clear.ml/docs/latest/docs/fundamentals/logger/) logger and also highlight how this code can be easily modified to make use of other loggers. You can see all the other loggers supported [here](https://pytorch.org/ignite/contrib/handlers.html#loggers).\n",
    "\n",
    "<!--more-->\n",
    "\n",
    "In this example, we will be using a simple convolutional network on the [MNIST](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.MNIST) dataset to show how logging works in Ignite.\n",
    "\n",
    "## Prerequisities\n",
    "- Refer to the [installation-guide](https://pytorch-ignite.ai/how-to-guides/01-installation/) to install Ignite (and Pytorch).\n",
    "- To get started with ClearML create your account [here](https://app.community.clear.ml/profile). Then create a credential: Profile > Create new credentials > Copy to clipboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! clearml-init # You may want to run this command on your terminal separately and paste what you copied in the step above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.contrib.handlers.clearml_logger import (\n",
    "    ClearMLLogger,\n",
    "    ClearMLSaver,\n",
    "    GradsHistHandler,\n",
    "    GradsScalarHandler,\n",
    "    WeightsHistHandler,\n",
    "    WeightsScalarHandler,\n",
    "    global_step_from_engine,\n",
    ")\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.handlers import Checkpoint\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.utils import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST(download=True, root=\".\", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        MNIST(download=False, root=\".\", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Ignite makes use of handlers to configure what we want to log. Each handler takes takes in some common attributes like:\n",
    "\n",
    "- Engine Object, which could for example be the trainer if we are interested in training logs\n",
    "- Event Name, through which we tell when do we want the information to be logged, for example `event_name=Event.ITERATION_COMPLETED(every=100)` would mean that we want the information to be logged every 100 iterations.\n",
    "- args (or kwargs), using which you pass some metadata and provide information of what is to be logged, for example to log the 'loss' we could pass `output_transform=lambda loss: {\"batchloss\": loss}`\n",
    "- Ignite also provides the flexibility to execute custom event handlers, these can be set with `log_handler` attribute of the `attach_output_handler`. For example, `log_handler=WeightsScalarHandler(model)` would log the norm of model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    device = \"cpu\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "\n",
    "    model.to(device) \n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    trainer.logger = setup_logger(\"Trainer\")\n",
    "\n",
    "    metrics = {\"accuracy\": Accuracy(), \"loss\": Loss(criterion)}\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    validation_evaluator.logger = setup_logger(\"Val Evaluator\")\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def compute_metrics(engine):\n",
    "        train_evaluator.run(train_loader)\n",
    "        validation_evaluator.run(val_loader)\n",
    "        \n",
    "    # To utilize other loggers we need to change the object here\n",
    "    clearml_logger = ClearMLLogger(project_name=\"examples\", task_name=\"ignite\") \n",
    "\n",
    "    # Attach the logger to the trainer to log training loss \n",
    "    clearml_logger.attach_output_handler(\n",
    "        trainer,\n",
    "        event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "        tag=\"training\",\n",
    "        output_transform=lambda loss: {\"batchloss\": loss},\n",
    "    )\n",
    "  \n",
    "    # Attach the logger to log loss and accuracy for both training and validation\n",
    "    for tag, evaluator in [(\"training metrics\", train_evaluator), (\"validation metrics\", validation_evaluator)]:\n",
    "        clearml_logger.attach_output_handler(\n",
    "            evaluator,\n",
    "            event_name=Events.EPOCH_COMPLETED,\n",
    "            tag=tag,\n",
    "            metric_names=[\"loss\", \"accuracy\"],\n",
    "            global_step_transform=global_step_from_engine(trainer),\n",
    "        )\n",
    "\n",
    "    # Attach the logger to the trainer to log optimizer's parameters, e.g. learning rate \n",
    "    clearml_logger.attach_opt_params_handler(\n",
    "        trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights norm\n",
    "    clearml_logger.attach(\n",
    "        trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights as a histogram \n",
    "    clearml_logger.attach(trainer, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "    # Attach the logger to the trainer to log modelâ€™s gradients as scalars\n",
    "    clearml_logger.attach(\n",
    "        trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n",
    "    )\n",
    "\n",
    "    #Attach the logger to the trainer to log model's gradients as a histogram    \n",
    "    clearml_logger.attach(trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "    handler = Checkpoint(\n",
    "        {\"model\": model},\n",
    "        ClearMLSaver(),\n",
    "        n_saved=1,\n",
    "        score_function=lambda e: e.state.metrics[\"accuracy\"],\n",
    "        score_name=\"val_acc\",\n",
    "        filename_prefix=\"best\",\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    )\n",
    "    validation_evaluator.add_event_handler(Events.EPOCH_COMPLETED, handler)\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "    clearml_logger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "val_batch_size=1000\n",
    "epochs=5 \n",
    "lr=0.01\n",
    "momentum=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=575b4d9b5c8a47589ac7edb7e5e0bb59\n",
      "ClearML results page: https://app.community.clear.ml/projects/4d6b8ac509bc46da91607e83011248fb/experiments/575b4d9b5c8a47589ac7edb7e5e0bb59/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages/ignite/contrib/handlers/clearml_logger.py:659: UserWarning: ClearMLSaver created a temporary checkpoints directory: /tmp/ignite_checkpoints_2021_10_25_20_21_50_gkx2f03c\n",
      "  warnings.warn(f\"ClearMLSaver created a temporary checkpoints directory: {dirname}\")\n",
      "2021-10-25 20:21:50,778 Trainer INFO: Engine run starting with max_epochs=5.\n",
      "2021-10-25 20:22:08,993 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:18,656 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:10\n",
      "2021-10-25 20:22:18,657 Train Evaluator INFO: Engine run complete. Time taken: 00:00:10\n",
      "2021-10-25 20:22:18,658 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:29,442 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:29,443 Val Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:29,444 Trainer INFO: Epoch[1] Complete. Time taken: 00:00:39\n",
      "2021-10-25 20:22:46,879 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:57,516 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:57,518 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:57,519 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:12,853 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:12,854 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:12,855 Trainer INFO: Epoch[2] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:23:29,609 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:40,388 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:23:40,390 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:23:40,390 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:55,842 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:55,845 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:55,845 Trainer INFO: Epoch[3] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:24:13,223 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:24:23,924 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:24:23,925 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:24:23,925 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:24:39,658 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:16\n",
      "2021-10-25 20:24:39,661 Val Evaluator INFO: Engine run complete. Time taken: 00:00:16\n",
      "2021-10-25 20:24:39,662 Trainer INFO: Epoch[4] Complete. Time taken: 00:00:44\n",
      "2021-10-25 20:24:57,385 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:25:07,264 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:10\n",
      "2021-10-25 20:25:07,265 Train Evaluator INFO: Engine run complete. Time taken: 00:00:10\n",
      "2021-10-25 20:25:07,267 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:25:22,536 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:25:22,537 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:25:22,538 Trainer INFO: Epoch[5] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:25:22,539 Trainer INFO: Engine run complete. Time taken: 00:03:32\n"
     ]
    }
   ],
   "source": [
    "run(batch_size, val_batch_size, epochs, lr, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed along, Congratulations! You can take a look at some of the visualisations from the results page mentioned in you logs above (`ClearML results page`). Here's an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Clear ML Dashboard](assets/clearml-dashboard.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
